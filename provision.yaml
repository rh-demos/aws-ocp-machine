- hosts: localhost
  connection: local
  gather_facts: False
  vars:
    security_group: MySecurityGroup-ansible
    region: eu-central-1
    ami_id: ami-062dacb006c5860f9
    #ami_id: ami-c86c3f23
  tasks:
  - name: Ensure a security group with correct ingress/egress rules are in place
    ec2_group:
      name: "{{ security_group }}"
      description: My security group
      region: "{{ region }}"
      rules:
        - proto: tcp
          from_port: 80
          to_port: 80
          cidr_ip: 0.0.0.0/0
        - proto: tcp
          from_port: 22
          to_port: 22
          cidr_ip: 0.0.0.0/0
        - proto: tcp
          from_port: 8443
          to_port: 8443
          cidr_ip: 0.0.0.0/0
        - proto: tcp
          from_port: 443
          to_port: 443
          cidr_ip: 0.0.0.0/0
        - proto: udp
          from_port: 53
          to_port: 53
          cidr_ip: 0.0.0.0/0
#      rules_egress:
#        - proto: all
#          cidr_ip: 0.0.0.0/0

  - name: Provision servers which are to be managed with Ansible
    ec2:
      key_name: my_key
      region: "{{ region }}"
      group: "{{ security_group }}"
      instance_type: t2.2xlarge
#      instance_type: t2.xlarge
      image: "{{ ami_id }}"
      wait: true
      exact_count: 1
      count_tag:
        identity: ocp-master
      instance_tags:
        identity: ocp-master
        kubernetes.io/cluster/openshift: owned
      volumes:
        - device_name: /dev/sda1
          volume_type: gp2
          volume_size: 100
          delete_on_termination: true 
    register: ec2instances
  - name: Wait for SSH to come up
    local_action: wait_for 
      host={{ item.public_ip }} 
      port=22 
      state=started
    with_items: "{{ ec2instances.tagged_instances }}"
  - name: Add all instance public IPs to host group
    add_host:
      hostname={{ item.public_ip }}
      groups=ec2instances
    with_items: "{{ ec2instances.tagged_instances }}"
- hosts: ec2instances
  remote_user: ec2-user
  become: true
  become_method: sudo
  vars:
    rh_username: "{{ lookup('env', 'RH_USER') }}"
    rh_password: "{{ lookup('env', 'RH_PASSWORD') }}"
    rh_poolid: "{{ lookup('env', 'RH_POOL_ID') }}"
  tasks:
  - name: Print IP addresses of regular systems
    debug:
      var=hostvars[inventory_hostname].ansible_fqdn
  - name: Subscribe the machine
    redhat_subscription:
      state: present
      username: "{{ rh_username }}"
      password: "{{ rh_password }}"
      pool_ids: "{{ rh_poolid }}"
  - name: Disable all repos
    shell: yum-config-manager --disable \* 
  - name: Enable needed repos
    shell: subscription-manager repos     --enable="rhel-7-server-rpms"     --enable="rhel-7-server-extras-rpms"     --enable="rhel-7-server-ose-3.11-rpms"     --enable="rhel-7-server-ansible-2.6-rpms"
  - name: Install required packages
    yum:
      name: wget,git,net-tools,bind-utils,yum-utils,iptables-services,bridge-utils,bash-completion,kexec-tools,sos,psacct,openshift-ansible
      state: latest
  - name: upgrade all packages
    yum:
      name: '*'
      state: latest
  - name: Install docker
    yum:
      name: docker-1.13.1
  - name: enable docker and ensure it is not masked
    systemd:
      name: docker
      enabled: yes
      masked: no
  - name: Make sure docker is running
    systemd: state=started name=docker
  - name: Generate ssh key for user
    user:
      name: ec2-user
      generate_ssh_key: yes
    register: ssh_generated_key
  - name: Add ec2-user to authorized keys
    authorized_key:
      user: ec2-user
      state: present
      key: "{{ ssh_generated_key.ssh_public_key }}"
  - name: tell the host about our servers it might want to ssh to
    shell: "ssh-keyscan {{ hostvars[inventory_hostname].ansible_fqdn }} >> /home/ec2-user/.ssh/known_hosts"
  - name: setup the hosts file
    template:
      src: roles/ocp/files/hosts.template
      dest: /etc/ansible/hosts
  - name: copy the install file to the server
    template:
      src: roles/ocp/files/install.sh
      dest: /home/ec2-user/install.sh
      mode: 0777
